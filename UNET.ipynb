{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNyhamBVJ+93lc/h+bQp+38"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Importazione dataset.py oltre ad installazione e importazione librerie necessarie"],"metadata":{"id":"UXxXNbZaGkEe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_uC5F_TjHZ5o"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","percorso =  \"/content/drive/MyDrive/Progetto_laboratorio\"\n","import sys\n","sys.path.append(percorso)\n","import fiona\n","import os\n","\n","!pip install rasterio\n","!pip install geopandas\n","!pip install matplotlib\n","\n","import pandas\n","import numpy\n","import torch\n","import torch.nn as nn\n","\n","!pip install torch torchvision\n","import torchvision.transforms.functional as TF\n","from dataset import Dataset\n"]},{"cell_type":"markdown","source":["#Implementazione modello\n"],"metadata":{"id":"U6eCtJthGuUb"}},{"cell_type":"code","source":["class DoubleConv(nn.Module):\n","  def __init__(self,in_channels,out_channels):\n","    super(DoubleConv,self).__init__()\n","    #eseguiamo due convoluzioni 2d consecutive, ciascuna seguita da una normalizzazione batch e funzione di attivazione ReLu\n","    self.conv = nn.Sequential(nn.Conv2d(in_channels,out_channels,3,1,1,bias=False),       #convoluzione 2d con kernel size 3x3, stride e padding 1\n","                              nn.BatchNorm2d(out_channels),                               #normalizzazione batch utile per stabilizzare e accelerare training\n","                              nn.ReLu(inplace=True),                                      #activation function applicata in-place\n","                              nn.Conv2d(out_channels,out_channels,3,1,1,bias=False),\n","                              nn.BatchNorm2d(out_channels),\n","                              nn.ReLu(inplace=True))\n","\n","  def forward(self,x):\n","    return self.conv(x)\n","\n","class UNET(nn.Module):\n","  def __init__(self,in_channels=6,out_channels=1, features=[64,128,256,512]):              #mettiamo 6 canali poichè per il problema di change detection dovremo passare le due immagini da analizzare concatenate sui tre canali\n","    super(UNET,self).__init__()                                                                                          #features sta a indicare il numero di canali di output per ogni livello della rete\n","    self.ups = nn.ModuleList()                                       #usiamo modulelist perchè andremo a memorizzare dei livelli convoluzionali\n","    self.downs = nn.ModuleList()\n","    self.pool = nn.MaxPool2d(kernel_size=2,stride=2)                  #pooling layer per ridurre la dimensione spaziale delle feature maps\n","\n","    #parte bassa della unet, cioè si fa l'estrazione delle caratteristiche dall'immagine\n","    for feature in features:\n","      self.downs.append(DoubleConv(in_channels, feature))\n","      in_channels = feature\n","\n","    #parte alta della unet, cioè ricostruisce l'immagine segmentata partendo dalle caratteristiche estratte dalla parte bassa. Usa strati di convoluzione trasposta\n","\n","    for feature in reverse(features):\n","      self.ups.append(nn.ConvTranspose2d(feature*2,feature,kernel_size=2,stride=2))\n","      self.ups.append(DoubleConv(feature*2,feature))\n","\n","    self.bottleneck = DoubleConv(features[-1],features[-1]*2)                           #prende l'ultimo set di features maps e lo trasforma in un set con li doppio dei canali per catturare caratteristiche piu complesse\n","    self.final_conv = NN.Conv2d(features[0],out_channels,kernel_size=1)                 #strato di convoluzione con kernel 1x1 per ridurre i canali al numero di classi di output desiderato\n","\n","\n","#definisce come i dati di input x vengono trasformati attraverso la cnn per produrre l'output\n","  def forward(self,x):\n","    skip_connections = []                             #lista per memorizzare le skip connections,quest'ultime aiutano la stabilità e la velocità di convergenza del modello e permettono di utilizzare informazioni a diversi livelli di astrazione per identificare grandi e piccoli cambiamenti\n","\n","    #itera sui blocchi di convoluzione della parte bassa\n","    for down in self.downs:\n","      x = down(x)                                 #applica down (cioè double convolution) su x\n","      skip_connections.append(x)\n","      x = self.pool(x)                           #per ridurre la dimensione della feature maps\n","\n","    x = self.bottleneck(x)                             #applichiamo il bottleneck e poi invertiamo l'ordine delle skip connections per utilizzarle nella parte alta\n","    skip_connections = skip_connections[::-1]\n","\n","    #itera sulla parte alta , quindi sui blocchi di convoluzione trasposta però in coppie\n","    for idx in range(0,len(self.ups),2):                        #iteriamo in passi di 2 perchè ogni livello ha la componente di conv transpose e doubleconv e a noi interessa solo la prima\n","      x = self.ups[idx](x)                                      #applica la conv transpose a x(upsampling)\n","      skip_connections = skip_connections[idx//2]\n","      if x.shape != skip_connections.shape:                     #verifichiamo se dimensioni corrispondono e in caso contrario ridimensioniamo x\n","        x = TF.resize(x,size=skip_connections.shape[2:])\n","\n","      concat_skip = torch.cat((skip_connection,x),dim=1)       #concateniamo x con la skip connection lungo la dimensione del canale per combinare informazioni dettagliate della parte bassa con quelle della parte upsampled\n","      x = self.ups[idx+1](concat_skip)                         #applichiamo il blocco doubleconv\n","\n","    return self.final_conv(x)                                #applichiamo uno strato di convoluzione con kernel 1x1 per ridurre il numero di canali all'output che ci serve\n","\n","\n","\n"],"metadata":{"id":"h13fIGr992uu"},"execution_count":null,"outputs":[]}]}