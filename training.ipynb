{"cells":[{"cell_type":"markdown","metadata":{"id":"AJYIJ5HmWjod"},"source":["#Mount del drive e installazione/importazione librerie necessarie"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"DPtGzvLLR0ZX"},"outputs":[],"source":["!pip install torch torchvision\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","percorso =  \"/content/drive/MyDrive/Progetto_laboratorio\"\n","import sys\n","sys.path.append(percorso)\n","import fiona\n","import os\n","\n","\n","!pip install rasterio\n","!pip install geopandas\n","!pip install matplotlib\n","!pip install albumentations\n","!pip install tqdm\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from tqdm import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import matplotlib.pyplot as plt\n","import torchvision.transforms.functional as TF\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ic8ddK3er1Nw","executionInfo":{"status":"ok","timestamp":1720533046166,"user_tz":-120,"elapsed":3587,"user":{"displayName":"mattia maucione","userId":"17344288059033491218"}}},"outputs":[],"source":["import importlib\n","import dataset\n","importlib.reload(dataset)\n","import model_unet\n","importlib.reload(model_unet)\n","import utils\n","importlib.reload(utils)\n","from dataset import Dataset\n","from model_unet import UNET\n","from utils import (\n","    save_checkpoint,\n","    load_checkpoint,\n","    check_precision,\n","    check_recall,\n","    check_f1,\n","    check_accuracy,\n","    check_metrics,\n","    get_loaders,\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"OXpXkptLqFup","executionInfo":{"status":"ok","timestamp":1720533051142,"user_tz":-120,"elapsed":1058,"user":{"displayName":"mattia maucione","userId":"17344288059033491218"}}},"outputs":[],"source":["#Hyperparameters\n","LEARNING_RATE = 1e-2\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","BATCH_SIZE = 5\n","NUM_EPOCHS = 10\n","NUM_WORKERS = 2\n","#IMAGE_HEIGHT = 256\n","#IMAGE_WIDTH = 256\n","PIN_MEMORY = True\n","LOAD_MODEL = False\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","TRAIN_DIR = percorso + '/Dataset/train'\n","VAL_DIR = percorso + \"/Dataset/validation\"\n","TEST_DIR = percorso + \"/Dataset/test\"\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"m9CXmppcYPRA","executionInfo":{"status":"ok","timestamp":1720533055135,"user_tz":-120,"elapsed":2,"user":{"displayName":"mattia maucione","userId":"17344288059033491218"}}},"outputs":[],"source":["import random\n","def set_seed(seed):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n"]},{"cell_type":"markdown","metadata":{"id":"dypGhFlzWgKR"},"source":["#Training modello"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ajEQNn4PR3v-","executionInfo":{"status":"ok","timestamp":1720533057375,"user_tz":-120,"elapsed":3,"user":{"displayName":"mattia maucione","userId":"17344288059033491218"}}},"outputs":[],"source":["def train_fn(loader, model, optimizer, loss_fn, scaler):\n","  loop = tqdm(loader)                                       #progress bar\n","\n","  for batch_idx, (data, targets) in enumerate(loop):                       #iteriamo sui batch forniti dal loader\n","    if (data.shape[1] != 6 and data.shape[3] == 6):\n","      data = data.permute(0,3,1,2)\n","    if (data.shape[1] != 6 and data.shape[2] != 6):\n","      data = data.permute(0,2,1,3)\n","    data = data.to(device = DEVICE)                                      #sposta i dati sul device , CPU o GPU\n","    targets = targets.float().unsqueeze(1).to(device = DEVICE)             #convertiamo targets in float e aggiungiamo una dimensione extra\n","    print(data.shape)\n","    print(targets.shape)\n","    # forward\n","    with torch.cuda.amp.autocast():                                     #abilita il mixed precision training\n","      predictions = model(data)                                            #calcoliamo predizioni\n","      loss = loss_fn(predictions, targets)                                 #calcoliamo la loss\n","\n","    # backward\n","    optimizer.zero_grad()                                                  #azzera i gradienti dell'optimizer\n","    scaler.scale(loss).backward()                                          #scala la loss e calcola i gradienti con backward\n","    scaler.step(optimizer)                                                 #aggiorna i parametri\n","    scaler.update()                                                        #aggiorna lo scaler\n","\n","    # update tqdm loop\n","    loop.set_postfix(loss = loss.item())                                     #aggiorna il progress bar con il valore della loss\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3JXdZzKzq76y"},"source":["#Prova del modello"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"4ve54QtUq7Rn","executionInfo":{"status":"ok","timestamp":1720533062647,"user_tz":-120,"elapsed":514,"user":{"displayName":"mattia maucione","userId":"17344288059033491218"}}},"outputs":[],"source":["def main():\n","  train_transform = A.Compose([\n","      A.Rotate(limit=35, p=1.0),\n","      A.HorizontalFlip(p=0.5),\n","      A.VerticalFlip(p=0.1),\n","      A.Normalize(\n","          mean=[0.0, 0.0, 0.0],\n","          std=[1.0, 1.0, 1.0],\n","          max_pixel_value=255.0,\n","      ),\n","      ToTensorV2(),\n","  ], is_check_shapes=False)\n","\n","  val_transform = A.Compose([\n","      A.Normalize(\n","          mean=[0.0, 0.0, 0.0],\n","          std=[1.0, 1.0, 1.0],\n","          max_pixel_value=255.0,\n","      ),\n","      ToTensorV2(),\n","  ], is_check_shapes=False)\n","\n","  model = UNET(in_channels=6, out_channels=1).to(device = DEVICE)\n","  loss_fn = nn.BCEWithLogitsLoss()\n","  optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=0.9*NUM_EPOCHS)                 #riduce il lr di 0.1 ad intervalli regolari\n","  scaler = torch.cuda.amp.GradScaler()\n","  set_seed(42)\n","\n","  train_loader, val_loader = get_loaders(percorso, BATCH_SIZE, train_transform, val_transform, num_workers=2, pin_memory=PIN_MEMORY)\n","  scaler = torch.cuda.amp.GradScaler()\n","\n","  if LOAD_MODEL:\n","    load_checkpoint(torch.load(\"model.pth.tar\"), model)\n","\n","  all_predictions = []\n","  all_targets = []\n","  print(\"Training\")\n","\n","  for epoch in range (NUM_EPOCHS):\n","    train_fn(loader=train_loader, model=model, optimizer=optimizer, loss_fn=loss_fn, scaler=scaler)\n","    for inputs,targets in val_loader:\n","      if (inputs.shape[1] != 6 and inputs.shape[3] == 6):\n","        inputs = inputs.permute(0,3,1,2)\n","      if (inputs.shape[1] != 6 and inputs.shape[2] != 6):\n","        inputs = inputs.permute(0,2,1,3)\n","      print(inputs.shape)\n","      print(targets.shape)\n","      inputs, targets = inputs.to(DEVICE),targets.to(DEVICE)\n","      outputs = model(inputs)\n","\n","\n","      all_predictions.append(outputs.cpu().detach().numpy())\n","      all_targets.append(targets.cpu().detach().numpy())\n","\n","      check_metrics(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy())\n","\n","\n","  scheduler.step()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":829},"executionInfo":{"elapsed":272154,"status":"error","timestamp":1720533344772,"user":{"displayName":"mattia maucione","userId":"17344288059033491218"},"user_tz":-120},"id":"crNVxJKLa1CQ","outputId":"3c802ceb-40c9-4155-d85b-59ee390c6982"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([5, 6, 1024, 1024])\n","torch.Size([5, 1, 1024, 1024])\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|█         | 1/10 [00:54<08:07, 54.11s/it, loss=0.93]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([5, 6, 1024, 1024])\n","torch.Size([5, 1, 1024, 1024])\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 2/10 [00:55<03:03, 22.97s/it, loss=0.728]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([5, 6, 1024, 1024])\n","torch.Size([5, 1, 1024, 1024])\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 3/10 [01:28<03:12, 27.50s/it, loss=0.828]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([5, 6, 1024, 1024])\n","torch.Size([5, 1, 1024, 1024])\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 4/10 [01:29<01:42, 17.10s/it, loss=0.637]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([5, 6, 1024, 1024])\n","torch.Size([5, 1, 1024, 1024])\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 5/10 [01:57<01:46, 21.25s/it, loss=0.606]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([5, 6, 1024, 1024])\n","torch.Size([5, 1, 1024, 1024])\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 6/10 [01:59<00:57, 14.42s/it, loss=0.531]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([5, 6, 1024, 1024])\n","torch.Size([5, 1, 1024, 1024])\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 7/10 [02:26<00:56, 18.72s/it, loss=0.428]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([5, 6, 1024, 1024])\n","torch.Size([5, 1, 1024, 1024])\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 8/10 [02:27<00:26, 13.13s/it, loss=0.373]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([5, 6, 1024, 1024])\n","torch.Size([5, 1, 1024, 1024])\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 9/10 [02:54<00:17, 17.28s/it, loss=0.336]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([3, 6, 1024, 1024])\n","torch.Size([3, 1, 1024, 1024])\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [02:56<00:00, 17.62s/it, loss=0.419]\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([5, 6, 1024, 1024])\n","torch.Size([5, 1024, 1024])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:952: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.88 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n","  return F.conv_transpose2d(\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 2.50 GiB. GPU ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-52488b72c43a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-b32cb2f0e6bb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Progetto_laboratorio/model_unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0mconcat_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_connection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m#concateniamo x con la skip connection lungo la dimensione del canale per combinare informazioni dettagliate della parte bassa con quelle della parte upsampled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_skip\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;31m#applichiamo il blocco doubleconv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.50 GiB. GPU "]}],"source":["\n","if __name__ == \"__main__\":\n","  try:\n","      torch.multiprocessing.set_start_method('spawn', force=True)\n","  except RuntimeError:\n","      pass\n","\n","  torch.cuda.empty_cache()\n","  main()\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMl6JfB95d12oNbMk76QAXE"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}